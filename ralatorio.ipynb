{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Disponibilização dos arquivos\r\n",
    "**Após a criação o índice, ele deve ser gravado em arquivo (inclusive o vocabulário). Favor disponibilizar o link para que eu possa fazer o download do arquivo (via dropbox, por ex). Além de instruções completas para que eu possa abrí­lo. A biblioteca json pode ajudar.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discussão \r\n",
    "A parte mais desafiadora foi entender a estrutura inicial do indexador. Em certas ocasiões tivemos divergências quanto a correta implementação dos métodos e isso levou a muito retrabalho e avanço lento. Por vezes não estava muito claro como proceder com os parâmetros e métodos auxiliares.\r\n",
    "\r\n",
    "# vantagem/desvantagem sobre os modelos comparativos \r\n",
    "Fazer a indexação totalmente pela memória principal poderia facilitar o acesso aos dados, mas pode exigir muito do hardware do computador e fica difícil prever o tamanho do espaço ocupado pois não se sabe quantas palavras em documentos diferentes existem. Já O uso de memória secundária vem como um alívio para memória RAM, porém acessar os dados depois salvos no arquivo binário `.idx` terá um custo associado a lentidão do disco rígido.\r\n",
    "\r\n",
    "# O modelo adotado para a solução\r\n",
    "A solução adotada nesse indexador vem buscar um equilíbrio entre uso de memória princípal e secundária. O foco era aproveitar a velocidade da principal e a grande capacidade de armazenamento da secundária, mas sempre intercalando entre elas.\r\n",
    "\r\n",
    "# Possíveis melhorias de eficiência e desempenho\r\n",
    "Para deixar o processo mais eficiente seria interessante indexar frases completas ao invés de palavras. Já para deixar diminuir o consumo de memória poderia ser feita uma codificação que abstraísse a informação salva como uma notação em hexadecimal.\r\n",
    "\r\n",
    "# Bibliotecas externas usadas\r\n",
    "Claro que houve uso de recurso externo já consolidado do acervo do Python para ajudar nessa tarefa. Ao todo são 5, sendo elas: gc, pickle, nltk, bs4 e string\r\n",
    "\r\n",
    "## gc\r\n",
    "Também conhecido como garbage colector, essa biblioteca foi usada para desabilitar o coletor de lixo durante a geração dos arquivos de forma a otimizar o acesso na memória secundária.\r\n",
    "\r\n",
    "## pickle\r\n",
    "Usada para escrita nos arquivos `.idx's`.\r\n",
    "\r\n",
    "## nltk\r\n",
    "Responsável por dividir o texto em tokens tendo `espace` como divisor. Além disso trazer o SnowballStemmer para realizar o stem das palavras filtradas.\r\n",
    "\r\n",
    "## bs4\r\n",
    "Responsável por remover marcadores de HTML do meio do texto.\r\n",
    "\r\n",
    "## string\r\n",
    "Não menos importante, essa biblioteca tem o papel de apontar todos os símbolos de pontuação através do atributo string.punctuation. A partir dele, foi possível obter todos os sinais que seriam removidos do texto.\r\n",
    "\r\n",
    "# Explicar a técnica de stemming adotada\r\n",
    "**Tem que explicar**\r\n",
    "\r\n",
    "# Estrutura utilizada    \r\n",
    "**Qual foi a estrutura do índice utilizado?** \r\n",
    "\r\n",
    "# Resultado obtido    \r\n",
    "Foram feitos dois testes de desempenho no em `TP2 - Dojo - Indice.ipynb`, no primeiro, os valores indexados não foram armazenados em arquivos. O teste inteiro ficou a cargo da memória principal. Para 2500 documentos e 500 termos obtidos por documento, foram obtidos os seguintes resultados: \r\n",
    "> Máximo 203.424927 MB de Memória RAM usada.\r\n",
    "\r\n",
    "> Indexou 1.250.000 ocorrências em 13.440106 segundos.\r\n",
    "\r\n",
    "Já no segundo teste, foi usado armazenamento em memória secundária. Sendo os mesmos 2500 documentos e 500 termos obtidos por documento, porém com limite de 100.000 termos na memória principal. Assim foram obtidos os seguintes resultados:\r\n",
    "> Máximo 20.528784 MB de Memória RAM usada.\r\n",
    "\r\n",
    "> Indexou 1.250.000 ocorrências em 1976.981396 segundos (33 minutos aprox.).\r\n",
    "\r\n",
    "> Foram gerados 12 arquivos `.idx`.\r\n",
    "\r\n",
    "> 164.748450 segundos para cada arquivo (3 minutos aprox.)."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}